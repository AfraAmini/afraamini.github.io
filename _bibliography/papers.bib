---
---
@inproceedings{vbon,
      title={Variational Best-of-N Alignment},
      author={Afra Amini and Tim Vieira and Ryan Cotterell},
      year={2024},
      abbr={arXiv},
      selected=true,
      booktitle = {arXiv},
      pdf = {https://arxiv.org/pdf/2407.06057v1},
      abstract={Best-of-N (BoN) is a popular and effective algorithm for aligning language models to human preferences. The algorithm works as follows: at inference time, N samples are drawn from the language model, and the sample with the highest reward, as judged by a reward model, is returned as the output. Despite its effectiveness, BoN is computationally expensive; it reduces sampling throughput by a factor of N. To make BoN more efficient at inference time, one strategy is to fine-tune the language model to mimic what BoN does during inference. To achieve this, we derive the distribution induced by the BoN algorithm. We then propose to fine-tune the language model to minimize backward KL divergence to the BoN distribution. Our approach is analogous to mean-field variational inference and, thus, we term it variational BoN (vBoN). To the extent this fine-tuning is successful and we end up with a good approximation, we have reduced the inference cost by a factor of N. Our experiments on a controlled generation task suggest that while variational BoN is not as effective as BoN in aligning language models, it is close to BoN performance as vBoN appears more often on the Pareto frontier of reward and KL divergence compared to models trained with KL-constrained RL objective.}
}

@inproceedings{odpo,
      title={Direct Preference Optimization with an Offset},
      author={Afra Amini and Tim Vieira and Ryan Cotterell},
      year={2024},
      abbr={ACL 2024},
      selected=true,
      booktitle = {Findings of the Association for Computational Linguistics: ACL 2024},
      pdf = {https://arxiv.org/pdf/2402.10571},
      abstract={Direct preference optimization (DPO) is a successful fine-tuning strategy for aligning large language models with human preferences without the need to train a reward model or employ reinforcement learning. DPO, as originally formulated, relies on binary preference data and fine-tunes a language model to increase the likelihood of a preferred response over a dispreferred response. However, not all preference pairs are equal: while in some cases the preferred response is only slightly better than the dispreferred response, there can be a stronger preference for one response when, for example, the other response includes harmful or toxic content. In this paper, we propose a generalization of DPO, termed DPO with an offset (ODPO), that does not treat every preference pair equally during fine-tuning. Intuitively, ODPO requires the difference between the likelihood of the preferred and dispreferred response to be greater than an offset value. The offset is determined based on the extent to which one response is preferred over another. Our experiments on various tasks suggest that ODPO significantly outperforms DPO in aligning language models, especially when the number of preference pairs is limited.}
}
@inproceedings{climate,
      title={Assessing Large Language Models on Climate Information},
      author={Jannis Bulian* and Mike S. Sch{\"a}fer* and Afra Amini* and Heidi Lam* and Massimiliano Ciaramita* and Ben Gaiarin* and Michelle Chen Huebscher* and Christian Buck* and Niels G. Mede* and Markus Leippold* and Nadine Strauss*},
      year={2024},
      abbr={ICML 2024},
      selected=false,
      pdf = {https://arxiv.org/pdf/2310.02932v2},
      booktitle = {International Conference on Machine Learning},
      abstract={Understanding how climate change affects us and learning about available solutions are key steps toward empowering individuals and communities to mitigate and adapt to it. As Large Language Models (LLMs) rise in popularity, it is necessary to assess their capability in this domain. In this study, we present a comprehensive evaluation framework, grounded in science communication principles, to analyze LLM responses to climate change topics. Our framework emphasizes both the presentational and epistemological adequacy of answers, offering a fine-grained analysis of LLM generations. Spanning 8 dimensions, our framework discerns up to 30 distinct issues in model outputs. The task is a real-world example of a growing number of challenging problems where AI can complement and lift human performance. We introduce a novel and practical protocol for scalable oversight that uses AI Assistance and relies on raters with relevant educational backgrounds. We evaluate several recent LLMs and conduct a comprehensive analysis of the results, shedding light on both the potential and the limitations of LLMs in the realm of climate communication.}
}

@inproceedings{du2023principled,
      title={Principled Gradient-based Markov Chain Monte Carlo for Text Generation},
      author={Li Du and Afra Amini and Lucas Torroba Hennigen and Xinyan Velocity Yu and Jason Eisner and Holden Lee and Ryan Cotterell},
      year={2024},
      abbr={ICML 2024},
      selected=true,
      booktitle = {International Conference on Machine Learning},
      pdf = {https://arxiv.org/pdf/2312.17710},
      abstract={Recent papers have demonstrated the possibility of energy-based text generation by adapting gradient-based sampling algorithms, a paradigm of MCMC algorithms that promises fast convergence. However, as we show in this paper, previous attempts on this approach to text generation all fail to sample correctly from the target language model distributions. To address this limitation, we consider the problem of designing text samplers that are faithful, meaning that they have the target text distribution as its limiting distribution. We propose several faithful gradient-based sampling algorithms to sample from the target energy-based text distribution correctly, and study their theoretical properties. Through experiments on various forms of text generation, we demonstrate that faithful samplers are able to generate more fluent text while adhering to the control objectives better.}
}
@inproceedings{liu-etal-2023-linear,
      title={Linear-Time Modeling of Linguistic Structure: An Order-Theoretic Perspective},
      author={Tianyu Liu and Afra Amini and Mrinmaya Sachan and Ryan Cotterell},
      year={2023},
      abbr={EMNLP 2023},
      selected=true,
      award={Outstanding Paper Award},
      booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
      publisher = {Association for Computational Linguistics},
      pdf = {https://aclanthology.org/2023.emnlp-main.52.pdf},
      abstract = {Tasks that model the relation between pairs of tokens in a string are a vital part of understanding natural language. Such tasks, in general, require exhaustive pair-wise comparisons of tokens, thus having a quadratic runtime complexity in the length of the string. We show that these exhaustive comparisons can be avoided, and, moreover, the complexity of such tasks can be reduced to linear by casting the relation between tokens as a partial order over the string. Our method predicts real numbers for each token in a string in parallel and sorts the tokens accordingly, resulting in total orders of the tokens in the string. Each total order implies a set of arcs oriented from smaller to greater tokens, sorted by their predicted numbers. The intersection of total orders results in a partial order over the set of tokens in the string, which is then decoded into a directed graph representing the desired linguistic structure. Our experiments on dependency parsing and coreference resolution show that our method achieves state-of-the-art or comparable performance. Moreover, the linear complexity and parallelism of our method double the speed of graph-based coreference resolution models, and bring a 10-times speed-up over graph-based dependency parsers.},
}

@inproceedings{amini2023structured,
      title={Structured Voronoi Sampling},
      author={Afra Amini and Li Du and Ryan Cotterell},
      year={2023},
      booktitle = {Proceedings Neural Information Processing Systems (NeurIPS)},
      pdf = {https://arxiv.org/pdf/2306.03061.pdf},
      abstract = {Recently, there has been a growing interest in the development of gradient-based sampling algorithms for text generation, especially in the context of controlled generation. However, there exists a lack of theoretically grounded and principled approaches for this task. In this paper, we take an important step toward building a principled approach for sampling from language models with gradient-based methods. We use discrete distributions given by language models to define densities and develop an algorithm based on Hamiltonian Monte Carlo to sample from them. We name our gradient-based technique Structured Voronoi Sampling (SVS). In an experimental setup where the reference distribution is known, we show that the empirical distribution of SVS samples is closer to the reference distribution compared to alternative sampling schemes. Furthermore, in a controlled generation task, SVS is able to generate fluent and diverse samples while following the control targets significantly better than other methods.},
      abbr={NeurIPS 2023},
      selected=true,
}

@inproceedings{amini2023hexatagging,
      title={Hexatagging: Projective Dependency Parsing as Tagging},
      author={Afra Amini* and Tianyu Liu* and Ryan Cotterell},
      year={2023},
      abbr={ACL 2023},
      selected=true,
      award={Outstanding Paper Award},
      booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics: Short Papers},
      publisher = {Association for Computational Linguistics},
      pdf = {https://arxiv.org/pdf/2306.05477.pdf},
      abstract = {We introduce a novel dependency parser, the hexatagger, that constructs dependency trees by tagging the words in a sentence with elements from a finite set of possible tags. In contrast to many approaches to dependency parsing, our approach is fully parallelizable at training time, i.e., the structure-building actions needed to build a dependency parse can be predicted in parallel to each other. Additionally, exact decoding is linear in time and space complexity. Furthermore, we derive a probabilistic dependency parser that predicts hexatags using no more than a linear model with features from a pretrained language model, i.e., we forsake a bespoke architecture explicitly designed for the task. Despite the generality and simplicity of our approach, we achieve state-of-the-art performance of 96.4 LAS and 97.4 UAS on the Penn Treebank test set. Additionally, our parserâ€™s linear time complexity and parallelism significantly improve computational efficiency, with a roughly 10-times speed-up over previous state-of-the-art models during decoding.}
}

@inproceedings{demonli,
      title={Which Spurious Correlations Impact Reasoning in NLI Models? A Visual Interactive Diagnosis through Data-Constrained Counterfactuals},
      author={Robin Chan and Afra Amini and Mennatallah El-Assady},
      year={2023},
      abbr={ACL 2023},
      selected=false,
      booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
      publisher = {Association for Computational Linguistics},
      pdf = {https://arxiv.org/pdf/2306.12146.pdf},
      abstract = {We present a human-in-the-loop dashboard tailored to diagnosing potential spurious features that NLI models rely on for predictions. The dashboard enables users to generate diverse and challenging examples by drawing inspiration from GPT-3 suggestions. Additionally, users can receive feedback from a trained NLI model on how challenging the newly created example is and make refinements based on the feedback. Through our investigation, we discover several categories of spurious correlations that impact the reasoning of NLI models, which we group into three categories: Semantic Relevance, Logical Fallacies, and Bias. Based on our findings, we identify and describe various research opportunities, including diversifying training data and assessing NLI models' robustness by creating adversarial test suites.}
}

@inproceedings{amini-etal-2022-pat,
    title = {On Parsing as Tagging},
    author = "Amini, Afra  and
      Cotterell, Ryan",
    abbr={EMNLP 2022},
    booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    year = {2022},
    publisher = {Association for Computational Linguistics},
    pdf = {https://arxiv.org/pdf/2211.07344.pdf},
    arxiv = {2211.07344},
    selected=true,
    abstract = {There have been many proposals to reduce constituency parsing to tagging in the literature. To better understand what these approaches have in common, we cast several existing proposals into a unifying pipeline consisting of three steps: linearization, learning, and decoding. In particular, we show how to reduce tetratagging, a state-of-the-art constituency tagger, to shift--reduce parsing by performing a right-corner transformation on the grammar and making a specific independence assumption. Furthermore, we empirically evaluate our taxonomy of tagging pipelines with different choices of linearizers, learners, and decoders. Based on the results in English and a set of 8 typologically diverse languages, we conclude that the linearization of the derivation tree and its alignment with the input sequence is the most critical factor in achieving accurate taggers.}
}

@article{amini2022naturalistic,
  title={Naturalistic Causal Probing for Morpho-Syntax},
  abbr={TACL 2022},
  author={Amini, Afra and Pimentel, Tiago and Meister, Clara and Cotterell, Ryan},
  journal={Transactions of the Association for Computational Linguistics},
  pdf={https://arxiv.org/pdf/2205.07043.pdf},
  arxiv={2205.07043},
  selected=false,
  year={2022},
  abstract = {Probing has become a go-to methodology for interpreting and analyzing deep neural models in natural language processing. Yet recently, there has been much debate around the limitations and weaknesses of probes. In this work, we suggest a naturalistic strategy for input-level intervention on real world data in Spanish, which is a language with gender marking. Using our approach, we isolate morpho-syntactic features from counfounders in sentences, e.g. topic, which will then allow us to causally probe pre-trained models. We apply this methodology to analyze causal effects of gender and number on contextualized representations extracted from pre-trained models -- BERT, RoBERTa and GPT-2. Our experiments suggest that naturalistic intervention can give us stable estimates of causal effects, which varies across different words in a sentence. We further show the utility of our estimator in investigating gender bias in adjectives, and answering counterfactual questions in masked prediction. Our probing experiments highlights the importance of conducting causal probing in determining if a particular property is encoded in representations.},
}

@inproceedings{meister-etal-2021-conditional,
    title = {Conditional {P}oisson Stochastic Beams},
    author = "Meister, Clara  and
      Amini, Afra  and
      Vieira, Tim  and
      Cotterell, Ryan",
    abbr={EMNLP 2021},
    booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
    year = {2021},
    address = {Online and Punta Cana, Dominican Republic},
    publisher = {Association for Computational Linguistics},
    pdf = {https://aclanthology.org/2021.emnlp-main.52.pdf},
    acl = {https://aclanthology.org/2021.emnlp-main.52},
    arxiv = {2109.11034},
    doi = {10.18653/v1/2021.emnlp-main.52},
    pages = {664--681},
    selected=false,
    abstract = {Beam search is the default decoding strategy for many sequence generation tasks in NLP. The set of approximate K-best items returned by the algorithm is a useful summary of the distribution for many applications; however, the candidates typically exhibit high overlap and may give a highly biased estimate for expectations under our model. These problems can be addressed by instead using stochastic decoding strategies. In this work, we propose a new method for turning beam search into a stochastic process: Conditional Poisson stochastic beam search. Rather than taking the maximizing set at each iteration, we sample K candidates without replacement according to the conditional Poisson sampling design. We view this as a more natural alternative to Kool et al. (2019){'}s stochastic beam search (SBS). Furthermore, we show how samples generated under the CPSBS design can be used to build consistent estimators and sample diverse sets from sequence models. In our experiments, we observe CPSBS produces lower variance and more efficient estimators than SBS, even showing improvements in high entropy settings.},
}

